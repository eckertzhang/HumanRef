name: "humanref"
exp_root_dir: "./Results"
seed: 0
prompt: ""
negative_prompt: "worst quality, low quality, blurry, lack of texture detail"
image_path: ""
tag: "${rmspace:${prompt},_}"

geo_prior_type: 'econ_smpl'
use_sdf_loss: true
use_local_rendering: false 
use_multi_denoise: true
attention_strategy: 0   # 0/1/2/3, 2 for full body attentiion, 3 for full image attention  


data_type: "humanref-datamodule"
data:  
  use_pidm_prior: false
  use_orthograph: true
  run_local_rendering: "${use_local_rendering}"
  radius: 1.0
  image_path: "${image_path}"
  prompt: "${prompt}"
  workspace: "${exp_root_dir}"
  geo_prior_type: "${geo_prior_type}"
  height: [64, 128, 256, 512]
  width: ${data.height}
  resolution_milestones: [1000, 2000, 3000]
  default_elevation_deg: 0.0
  default_azimuth_deg: 0.0
  default_camera_distance: 1.0
  default_fovy_deg: 60.0
  ckpt_pidm: ""
  save_dir_pidm: ""
  random_camera: # threestudio/data/uncond.py -> RandomCameraDataModuleConfig
    batch_size: 1
    height: ${data.height}
    width: ${data.height}
    resolution_milestones: ${data.resolution_milestones}
    eval_height: 512
    eval_width: 512
    eval_batch_size: 1
    elevation_range: [-20, 20] 
    azimuth_range: [-180, 180]
    camera_distance_range: [0.8, 1.2] 
    fovy_range: [40.0, 70.0]   ## for perspective rendering, default:[40.0, 70.0]
    camera_perturb: 0.0
    center_perturb: 0.0
    up_perturb: 0.0
    light_position_perturb: 1.0
    light_distance_range: [7.5, 10.0]
    light_sample_strategy: "dreamfusion"
    use_orthograph: ${data.use_orthograph}
    radius: ${data.radius}

    eval_elevation_deg: ${data.default_elevation_deg}
    eval_camera_distance: ${data.default_camera_distance}
    eval_fovy_deg: ${data.default_fovy_deg}
    batch_uniform_azimuth: False
    n_val_views: 4
    n_test_views: 120

system_type: "humanref-system-sdf"
system:
  stage: coarse
  warm_up_iters: 600
  albedo_iters: 6000
  max_iters: ${trainer.max_steps}
  use_style_loss: false
  use_multi_denoise: "${use_multi_denoise}"
  run_initial: true
  run_local_rendering: "${use_local_rendering}"
  attention_strategy: "${attention_strategy}"

  ## Geometry: output density/feature from points
  geometry_type: "implicit-sdf-humanref"
  geometry:
    radius: "${data.radius}"
    use_orthograph: ${data.use_orthograph}
    normal_type: finite_difference
    shape_init: "mesh"
    out_sdf_loss: "${use_sdf_loss}"
    out_sdf_smooth_loss: true
    out_eikonal_loss: false
    geo_prior_type: "${geo_prior_type}"
    image_path: "${image_path}"
    shape_init_params: 1.0
    fov: ${data.default_fovy_deg}
    sdf_bias: 0.
    sdf_bias_params: 0.5

    ###### SDF network 1-3 (hierarchical)
    predict_offset: true
    sdf_select_level: 8
    pos_encoding_config:
      otype: HierHashGrid  # TCNNEncoding
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 16
      per_level_scale: 1.447269237440378  # max resolution 4096
    mlp_network_config:
      otype: "VanillaMLP"
      activation: "ReLU"
      output_activation: "none"
      n_neurons: 64
      n_hidden_layers: 2
  
  ## Material: output color from feature
  material_type: "no-material"
  material:
    n_output_dims: 3
    color_activation: sigmoid

  ## Background: output background color via 'SphericalHarmonics' encoding
  background_type: "neural-environment-map-background"
  background:
    n_output_dims: 3
    color_activation: sigmoid
    mlp_network_config:
      otype: "VanillaMLP"
      activation: "ReLU"
      n_neurons: 64
      n_hidden_layers: 2

  ## Renderer
  renderer_type: "neus-volume-renderer-humanref"
  renderer:
    radius: ${system.geometry.radius}
    num_samples_per_ray: 512 
    cos_anneal_end_steps: ${trainer.max_steps}
    eval_chunk_size: 65536   # 8192
    learned_variance_init: 0.3 
    use_volsdf: true 
    grid_prune: true   # default: true, both for pruning grid_sampling &&& for masking some low_alpha points
    prune_alpha_threshold: true   # default: true, only for masking some low_alpha points

  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    pretrained_model_name_or_path: "stable-diffusion-v1-5"
    prompt: "${prompt}"
    negative_prompt: "${negative_prompt}"
    use_perp_neg: false
    front_threshold: 30.
    back_threshold: 30.
  
  guidance_type: "stable-diffusion-clip-guidance-refsds"
  guidance:
    pretrained_model_name_or_path: "stable-diffusion-v1-5"
    guidance_scale: 7.
    weighting_strategy: sds 
    min_step_percent: 0.2
    max_step_percent: 0.6
    attention_auto_machine_weight: 1.0
    gn_auto_machine_weight: 1.0
    style_fidelity: 0.0
    reference_attn: true
    reference_adain: false
    attention_strategy: "${attention_strategy}"

  loggers:
    wandb:
      enable: false
      project: "threestudio"
      name: None

  loss:
    lambda_img: 10000.        
    lambda_normal: 10. 
    lambda_IoU: 1. 
    lambda_sdf: 100.
    lambda_sdf_smooth: 1.0   
    lambda_clip: 1.0
    lambda_multi: 20.
    lambda_2d_normal_smooth: 5.
    lambda_3d_normal_smooth: 2.

    ## SDS loss
    lambda_sds: 0.01   
    lambda_ref_sds: 1.e-3
    lambda_ref_vsd: 1.e-3
    lambda_ctrl_ref_sds: 1.e-5   
    lambda_unclip_sds: 0.001      
    lambda_pidm: 0.01          
    lambda_vsd: 0.01           
    lambda_lora: 1.

    ## Others
    lambda_back_cloth: 0.0   
    lambda_style: 0.0
    lambda_eikonal: 0.0      
    lambda_pidm_clip: 0.0     
    lambda_depth: 0.0
    lambda_orient: 0.0              
    lambda_sparsity: 0.0
    lambda_opaque: 0.0
    lambda_z_variance: 0.0          
  
  optimizer:
    name: Adam 
    args:
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      geometry.encoding:
        lr: 0.001 
      geometry.encoding_rgb:
        lr: 0.001
      geometry.common_net:
        lr: 0.001    
      geometry.sdf_network:
        lr: 0.001
      geometry.feature_network:
        lr: 0.001
      geometry.normal_network:  # needless
        lr: 0.001
      background:
        lr: 0.001
      renderer:
        lr: 0.001
      guidance:
        lr: 0.0001

trainer:
  max_steps: 12000
  log_every_n_steps: 1
  num_sanity_val_steps: 0 
  val_check_interval: 1000
  enable_progress_bar: true
  precision: 32

checkpoint:
  save_last: true
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
